# Assignment 3 
## Seq_to_Seq without attention
We have implemented the encoder-decoder model without the attention. Stacked encoder-decoder model have been built here.
## Setup and Installations
- These codes have been built up with ipynb in google colab.
- This book can be downloaded, uploaded adn run again by anyone.
